---
applyTo: '**'
---
# Instru√ß√µes para Desenvolvimento de Agentes de IA

## Contexto do Projeto
Voc√™ est√° trabalhando em projetos de Agentes de IA que utilizam:
- **LangChain/LangGraph** para workflows inteligentes
- **Firecrawl** para web scraping e extra√ß√£o de dados
- **OpenAI GPT-4** para processamento de linguagem natural
- **Pydantic** para valida√ß√£o e estrutura√ß√£o de dados
- **MCP (Model Context Protocol)** para integra√ß√£o de ferramentas

## Diretrizes Gerais

### üéØ Foco em Qualidade
- Sempre priorize c√≥digo limpo, leg√≠vel e bem documentado
- Use type hints em todas as fun√ß√µes e classes
- Implemente tratamento de erros robusto
- Escreva testes unit√°rios quando necess√°rio

### üîß Padr√µes T√©cnicos

#### Estrutura de Projeto
```
projeto/
‚îú‚îÄ‚îÄ .env                 # Vari√°veis de ambiente
‚îú‚îÄ‚îÄ main.py             # Ponto de entrada
‚îú‚îÄ‚îÄ requirements.txt    # Depend√™ncias
‚îî‚îÄ‚îÄ src/
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îú‚îÄ‚îÄ workflow.py     # L√≥gica principal
    ‚îú‚îÄ‚îÄ models.py       # Modelos Pydantic
    ‚îú‚îÄ‚îÄ prompts.py      # Templates de prompts
    ‚îî‚îÄ‚îÄ services/       # Integra√ß√µes externas
```

#### Modelos Pydantic
- Use tipos Optional para campos que podem estar ausentes
- Forne√ßa valores default apropriados
- Documente campos complexos com Field(description="...")
- Valide dados de entrada com validators personalizados

#### Workflows LangGraph
- Separe cada etapa em nodes distintos
- Use StateGraph com modelos Pydantic como state
- Implemente edge conditions quando necess√°rio
- Adicione logging para debug do fluxo

#### Integra√ß√£o APIs
- Sempre use vari√°veis de ambiente para chaves de API
- Implemente retry logic com exponential backoff
- Use async/await consistentemente
- Valide responses antes de processar

### üõ†Ô∏è Ferramentas Espec√≠ficas

#### Firecrawl
- Use ScrapeOptions com formats=['markdown'] para melhor extra√ß√£o
- Limite search results (3-5) para performance
- Implemente timeout adequado para scraping
- Cache results quando poss√≠vel

#### OpenAI
- Use temperature=0 para consist√™ncia em an√°lises
- Para structured output, sempre use with_structured_output()
- Implemente token counting para controle de custos
- Use system messages para definir comportamento

#### MCP
- Configure server_params com env vars corretas
- Use ClientSession com context managers
- Implemente initialize() antes de usar tools
- Trate disconnections gracefully

### üìù Conven√ß√µes de C√≥digo

#### Nomenclatura
- Classes: `PascalCase` (ex: `CompanyAnalysis`)
- Fun√ß√µes/vari√°veis: `snake_case` (ex: `extract_tools`)
- Constantes: `UPPER_CASE` (ex: `MAX_RETRIES`)
- Arquivos: `snake_case.py`

#### Imports
```python
# Standard library
import os
import asyncio

# Third-party
from langchain_openai import ChatOpenAI
from pydantic import BaseModel

# Local imports
from .models import ResearchState
from .services.firecrawl import FirecrawlService
```

#### Error Handling
```python
try:
    result = await api_call()
    return result
except SpecificError as e:
    logger.error(f"Specific error: {e}")
    return fallback_value
except Exception as e:
    logger.error(f"Unexpected error: {e}")
    raise
```

### üîç Debugging e Logging
- Use logging em vez de print() para debug
- Implemente progress indicators para opera√ß√µes longas
- Log requests/responses de APIs (sem expor keys)
- Use structured logging para an√°lise posterior

### üöÄ Performance
- Use asyncio.gather() para opera√ß√µes paralelas
- Implemente caching para dados que n√£o mudam
- Limite concurrent requests para APIs externas
- Use pagination quando dispon√≠vel

### üîí Seguran√ßa
- Nunca commite chaves de API
- Use .env para todas as configura√ß√µes sens√≠veis
- Valide e sanitize inputs de usu√°rio
- Implemente rate limiting adequado

### üìä An√°lise de Dados
- Estruture dados em modelos Pydantic consistentes
- Use type hints para clareza
- Implemente valida√ß√£o de dados robusta
- Forne√ßa fallbacks para dados ausentes

## Exemplos de Uso

### Criando um Workflow
```python
from langgraph.graph import StateGraph
from .models import ResearchState

def create_workflow():
    graph = StateGraph(ResearchState)
    graph.add_node("extract", extract_step)
    graph.add_node("research", research_step)
    graph.add_edge("extract", "research")
    return graph.compile()
```

### An√°lise com LLM
```python
async def analyze_content(content: str) -> CompanyAnalysis:
    structured_llm = self.llm.with_structured_output(CompanyAnalysis)
    
    messages = [
        SystemMessage(content=ANALYSIS_PROMPT),
        HumanMessage(content=f"Analyze: {content}")
    ]
    
    return await structured_llm.ainvoke(messages)
```

### Scraping com Firecrawl
```python
def scrape_with_fallback(url: str) -> Optional[str]:
    try:
        result = self.firecrawl.scrape_url(
            url,
            formats=["markdown"],
            timeout=30
        )
        return result.markdown
    except Exception as e:
        logger.warning(f"Scraping failed for {url}: {e}")
        return None
```

## Checklist de Qualidade
- [ ] Type hints em todas as fun√ß√µes
- [ ] Tratamento de erros implementado
- [ ] Vari√°veis de ambiente documentadas
- [ ] Logs informativos adicionados
- [ ] Modelos Pydantic validados
- [ ] Async/await usado consistentemente
- [ ] Performance otimizada
- [ ] Testes b√°sicos criados